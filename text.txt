1. bert模型预训练
垂搜box其实面对的是服务类需求的query，比如社保医保办理、买车票、找音乐或者电影、查地图等等，所以整体上query的分布和常规的预训练大模型是有比较大差异的。另外，服务类query有自己特有的领域知识，比如一些政务类机构、实体名词等。因此针对搜索场景下的各个垂搜box，有必要针对这个场景做定制的预训练模型来增强模型对这个场景的语义理解。我们的大模型会用在包括意图识别、文本相关性以及召回等场景中。
具体的优化方法有两点1. 训练数据：在通用语料的基础上，加入微信场景语料，另外融入服务知识图谱信息（我们构建了一个服务知识图谱，包括政务（账号、医保、社保等）、家政（电器维修、保洁等）、娱乐（影视、音乐、读书）、旅游（酒店、景点等）、工具（天气、日历）等）。2. 训练方式，实体masking，增加类目信息的embedding，比如修空调空调上门维修，空调实体可能会被mask掉，空调上门维修就是个家政类目的服务，会被打上家政的maker embedding。

2. 垂搜box意图模型
a. 样本构建。因为我们有非常多的类目，样本的自动打标以及一个高质量的训练样本是非常重要的。这里我们使用用户行为来辅助我们进行自动的样本打标，主要包括以下几种方式：1. query高曝光doc的类目分布；2. query高曝光doc的关键词分布；3. 竞品的曝光情况；
b. query大部分是短文本，因此蕴含有限的文本信息，不足以做好意图分类。因此我们选择在query后拼接用户的高点doc title / 摘要 / 类目或者是百科的摘要或者是公众号的描述等来增强语义信息。这里可以讲下将停用词删除。动态摘要，如果文章title过长的话，选择和query有重复text的部分。
c. 多类目模型联合训练，因为我们类目比较多，如果一个类目训练一个bert的话对资源的要求比较大，因此我们采用了mmoe的结构对同一个大类下的子类目进行联合训练。共享底层的bert，通过mmoe的结构来实现对不同类目的预测。
d. 模型结构，目前我们线上使用的是bert 12层的模型。

3. LLM模型的实践
a. 主要是针对意图和实体解析两个任务进行实践。因为我们有现成的query和意图的用户的行为数据，所以训练数据是非常丰富的。由于大模型有非常强大的语义理解能力，所以我们将原来的意图分类和实体解析任务融为一体，将分类问题转化为开放场景的生成任务。
b. 在娱乐上做了尝试，主要包括影视、音乐和读书这几个类目，通过现有的用户行为我们可以拿到query以及doc数据，以及doc的实体数据。那么我们可以通过这些样本构建prompt。现在你是一名专业的文本分析专家，下面我将给你一个query和一个text，你需要仔细分析text中的内容，然后判断query是否与音乐、影视或者书籍相关。你需要首先回答是或者否，如果你找不到线索，请回答否，并给出你的判断理由。
c. 我们在llama-7b和腾讯自研的7b和176b-lora上做了sft实验，整体上是超越目前线上bert模型的。
