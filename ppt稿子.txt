大家好，我是陆鑫益，来自nbase的搜索团队，我这次答辩主要分为个人简介，椰子搜索精排部分的介绍，这个项目的难点以及我的解决方案，接着是我所做的其他的一些工作，最后是提问环节。

我2020年6月毕业于华南理工大学的控制工程专业，2019年的暑期在qq浏览器的内容理解组实习，拿到offer后，2020年5月开始在大数据组实习，7月正式入职，后来在8月加入到nb搜索做精排模型的开发和优化以及一些数据分析的工作。

对于一个电商来说，搜索是一个比较重要的环节，它起到了高效连接用户和商品的桥梁的作用，一个优秀的电商搜索引擎，他的目的是帮助用户明确自己的搜索意图，降低用户的搜索成本，这就要求我们的搜索系统能够理解和满足不同用户个性化的需求，只有及时恰当的满足了用户的搜索需求，才能够进一步的促进用户进行下单购买，从而提升平台的gmv。

根据用户输入的query词，搜索引擎从商品库中进行商品召回，通过粗排和精排打分后按照一定的排序呈现给用户，其中粗排主要解决相关性问题，精排主要提供个性化排序。那么为什么要做精排呢？因为精排模型能够结合用户个性化的特征和平台商品的特性，在大量同质化的商品中通过调整排序去更好的满足用户独特的偏好，从而促进用户对商品的点击和转化，最终提升平台的收益。

目前椰子的搜索排序的架构主要如图所示，在用户输入query后，首先对query进行纠错、同义词扩展以及分词，接着去商品库中按照商品标题进行召回。在粗排阶段，主要考虑商品的相关性问题，我们会按照相关性对召回的商品进行分档，之后精排会在每一个档内对商品进行重新排序，最终展现给用户。

刚开始从零到一搭建精排模型面临许多难点，主要的问题是数据太少，并且通过搜索带来的点击和成交的样本更是十分的稀疏。

下面就谈一下搜索精排从零到一的迭代过程。首先我们调研了一下业界现有的一些方案，从最初的规则模型到LR模型再到现阶段大规模使用的深度模型，比如DeepFM和DIN等等。模型的结构更加复杂，性能不断提升，但是对数据的要求也在不断的变大。

结合我们平台的情况，搜索精排的迭代过程也有几个里程碑的时间点，我们从2020年8月开始积累搜索训练数据，在9月份引入了搜索相关性特征，在10月份有了一定数量的点击样本后开始通过模型去细致刻画用户兴趣变化，在11月左右样本数量到了千万的数量级，我们开始使用商品id特征做更复杂的交互。这期间线上的精排模型共经历了三次大的版本迭代，从最初的FM-DIN模型到加入transformer结构做更细致的用户行为序列挖掘再到切换id类的特征做深度特征交叉，三个模型AB实验分别较各自对照组提升了9.81，5.35和5.51。目前我们正在尝试多兴趣建模和多目标模型的优化，主要考虑的是在保证用户点击的情况下，促进用户购买的转化，从而提升平台整体的gmv。通过精排模型的优化，以及粗排相关性能力的提升，当然也有平台商品丰富度的提升等原因，目前在平消期的pvctr呈现的是一个稳定提升的态势，从最初8月份的2.x到目前稳定在6，7左右。

下面就针对精排模型的迭代过程做一些详细的介绍。刚开始由于数据量的问题，我们选用的是FM+DIN的模型结构。FM侧对不同领域的特征进行自动的二阶组合，包括用户特征和商品特征。比如用户id和商品价格的组合，可以在一定程度上表示用户的价格偏好等等。用户特征包括用户id，性别，地域等，商品特征包括商品类目、商品价格、历史销量，历史点击率等。din侧，由于数据量偏少的问题，如果直接使用用户点击的商品id进行训练的话，会面临训练不充分的问题。因为平台有几万的商品id，并且大部分商品是长尾商品，训练样本很少。因此这里我们采用用户点击的商品三级类目id作为din的输入，这样既可以提供一定的用户历史行为信息，又保证了训练的有效性。用户当前的搜索意图与历史行为是存在一定的相关性的，din通过attention unit的权重大小来表示当前意图与历史点击序列之间的相关程度。如果当前用户在搜索手机类目相关的商品，那么该用户历史点击过的手机类目商品会对最终的排序产生较大的影响。

FM+DIN模型在AB实验中相比较不做精排的对照组，pvctr提升了9.81%，因此，搜索精排的收益是十分可观的。

从DIN的模型结构中，我们可以发现一个很明显的问题，din认为用户序列中的每一个点击行为是独立的，并没有考虑序列之间的相互联系，这就造成了模型对于用户历史行为的理解是不够充分的。举一个简单的例子，对于数码类目，用户三天前点击了几个手环，10分钟前点击了大量的手机，那么当用户再次进行数码相关的搜索时，从我们直观的经验上来说，历史点击中手机对于当前搜索的影响肯定是大于手环的。所以我们需要考虑序列中各个节点之间相互影响，包括时间衰减效应和序列整体的信息。因此我们在下一版模型中引入了自然语言处理中常用transformer结构。transformer最关键的模块是多头自注意力机制，输入为每个节点的embedding+节点的位置信息，自注意力机制将序列中的每一个节点与其他节点做点积，再通过softmax算出每一个节点的自注意力权重，由于算权重的过程中考虑序列中其他节点的信息，因此最终输出的每一个节点也包含了整个序列的信息。

在模型训练完后，我对比前后两个模型din权重的变化，对于相同的训练数据，用同一个输入，可以看到，当打分商品为redmi k30时，没有transformer结构的模型，同属于手机类目的p40，小米，iphone的响应是比较高的，这符合我们的预期。当加入transformer结构后，同为手机类目的这几个商品的响应进一步提升，并且越近的点击响应越大，也就是我们的模型有了时间衰减的效应。这与我们最初的期望是一致的。

同时，这一版模型中我们加入了搜索query与商品标题的相关性特征，包括语义相关性得分，字符统计类特征等，可以看到，当时粗排部分的相关性做的并不够完美，搜iphone11的时候会出来手机壳，搜airpods的时候会出来一些白牌耳机，但通过精排的重新打分，可以将大部分badcase消除。

最终线上AB实验pvctr的提升大约在5%左右。

11月份的时候，搜索的训练数据量积累到了千万级别，对于用户序列的挖掘，我们从最初的类目id切换到了商品id，从理论上来讲，如果训练充分，商品id的embedding就能够完全涵盖这个商品的类目、品牌和价格等基础特性。为了让商品idembedding训练的更充分，我们在商品特征的维度上对embedding做了深度的交叉，目的是为了增加embedding参数的迭代次数。有评委可能会问为什么在transofrmer的输出上做特征交叉，而不在原始embedding做交叉或者din的输出上做交叉？相关的实验我们都做过，如果仅做一层交叉的话在transformer后的测试集表现是最好的。当然如果全部三层都做交叉的话测试集表现是最优的，但考虑到线上部署的效率问题，我们这里只采用一层交叉。
为了验证idembedding训练的有效性，我对idembedding做了降维聚类可视化，可以发现类目相同或者相近的embedding都明显的聚集在了一起，因此整体来看对于idembedding的训练是比较有效的。

最终的AB是在双十二活动期间做的，pvctr较上一个版本大约有5.5左右的提升。

以上就是我在搜索精排模型方面的工作，我的其他一些工作包括搜索侧的数据分析，包括整个搜索灯塔看板的搭建、各项搜索指标监控等，以及研发侧的埋点等。另一个是召回侧的同义词挖掘，我会根据搜索的日志挖掘一些搜索场景下的常见的同义词词典，用于在query改写时扩大搜索的召回；最后是搜索发现模块的上线，主要是根据用户历史行为去推荐个性化的搜索query，激发用户搜索的欲望，目前AB是能够提升一定的pvcvr和整体的gmv。

最后说一下未来的工作规划，首先是搜索特征的丰富，主要是和推荐、大数据和内容理解进行合作，推动商品首图质量分，商品评价数量，评分，物流等特征的完善，在这个基础上会衍生出商品静态质量分作为商品的一个非常重要的基础特征。第二对于ctr模型，目前我们仅从用户点击序列去挖掘用户偏好，用户点击行为更多的是代表用户的短期偏好，用户的收藏和购买可以理解为用户的中长期比较稳定的偏好。所以我们正在做的是用户的多兴趣模型。第三我们需要关注用户的成交和平台的效益问题，所以要提升用户的成交转化，这涉及到多任务学习多目标模型的优化，并且如何取得各个目标之间的平衡以及线上打分方式的设计依旧需要做更多的尝试。最后，近期我们上线了搜索补全模块，在搜索发现和补全中，根据用户不同的偏好进行针对性的推荐和补全是非常重要的，这其实也是排序的另外一类应用，如何将商品排序的方案迁移到query和补全词的排序，是我后面工作的一个重点。

最后是我在工作过程中的一些文档输出，包括同义词挖掘的技术文档，搜索发现模块使用的querybase库的构建、算法模型的说明文档以及ab实验报告，和在大数据做的一些异常检测和归因分析的调研等。
这就是我这次答辩的全部内容，请各位评委老师批评指正。谢谢大家。


















